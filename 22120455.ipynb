{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "editable": true,
    "id": "GUvdvAaASzmD",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Lab 03: Cây quyết định"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Họ tên: Nguyễn Tường Bách Hỷ\n",
    "- MSSV: 22120455"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**LƯU Ý:**</font>\n",
    "\n",
    "- Bài làm của sinh viên phải do chính bản thân sinh viên tự làm, có thể trao đổi và tham khảo ý tưởng nhưng không được sao chép (một phần hoặc toàn bộ) code hoặc lời giải từ bất cứ người nào khác. Nếu vi phạm sẽ bị <font color='red'>0đ</font> bài tập này.\n",
    "- Các bạn có thể tạo thêm các cell trong quá trình code, tuy nhiên các bạn vui lòng <font color='red'>không xóa các cell code mặc định và các cell test case</font> (vì có thể ảnh hưởng đến kết quả khi chấm bài).\n",
    "- Các test case được đưa ra chỉ nhằm mục đích giúp các bạn test code của mình, <font color='red'>**việc pass các test case này không đồng nghĩa với việc lời giải của các bạn sẽ đạt điểm tối đa**</font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cách làm bài**\n",
    "\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này; trong file, từ `TODO` để cho biết những phần mà bạn cần phải làm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Cách nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Kernel` - `Restart Kernel & Run All Cells`, để restart và chạy tất cả các cell trong notebook của các bạn; do đó, trước khi nộp bài, các bạn nên chạy thử `Kernel` - `Restart Kernel & Run All Cells` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, các bạn tạo thư mục nộp bài theo cấu trúc sau:\n",
    "\n",
    "- Thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`)\n",
    "    - File `HW03.ipynb` (Đổi tên file notebook này theo MSSV của bạn)\n",
    "\n",
    "Cuối cùng, các bạn nén thư mục `MSSV` này lại và nộp ở link trên moodle. **Đuôi của file nén phải là .zip (chứ không được .rar hay gì khác).**\n",
    "\n",
    "<font color=red>Các bạn lưu ý tuân thủ chính xác qui định nộp bài ở trên.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nội dung bài tập**\n",
    "\n",
    "Bài tập 3 là bài tập cá nhân. Trong bài này, bạn sẽ cài đặt thuật toán học máy: \n",
    "1. Cây quyết định (Decision tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYefhgwoSzmZ"
   },
   "source": [
    "### Tải những thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXTmvF6JSzmb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from zlib import adler32\n",
    "from typing import Tuple, List\n",
    "import requests\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import sklearn.datasets as datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init seed\n",
    "seed = 2024\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tải tập dữ liệu về thuốc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy tưởng tượng rằng bạn là một nhà nghiên cứu y khoa đang biên soạn dữ liệu cho một nghiên cứu. Bạn đã thu thập dữ liệu về một nhóm bệnh nhân, tất cả đều mắc cùng một căn bệnh. Trong quá trình điều trị, mỗi bệnh nhân đều đáp ứng với một trong 5 loại thuốc, Thuốc A, Thuốc B, Thuốc c, Thuốc x và thuốc y.\n",
    "\n",
    "Một phần công việc của bạn là xây dựng một mô hình để tìm ra loại thuốc nào có thể phù hợp với bệnh nhân tương lai mắc cùng một căn bệnh. Các đặc điểm của tập dữ liệu này là Tuổi, Giới tính, Huyết áp và Cholesterol của bệnh nhân, và mục tiêu là loại thuốc mà mỗi bệnh nhân đáp ứng.\n",
    "\n",
    "Đây là một mẫu của bộ phân loại đa lớp và bạn có thể sử dụng tập dữ liệu để xây dựng một cây quyết định, sau đó sử dụng nó để dự đoán lớp của một bệnh nhân chưa biết hoặc kê đơn thuốc cho một bệnh nhân mới."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CO6JKObwSzmn"
   },
   "source": [
    "### Đọc tập dữ liệu về thuốc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viết hàm `drug_dataloader` để load tập dữ liệu từ tập tin `drug200_numeric.csv` và trả về hai mảng numpy array `features` và `classes` đại diện cho đặc trưng và lớp tương ứng. Lưu ý, không sử Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "6EFp9Jl3Szmo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "354fea915de738db30523ac01a77fa1b",
     "grade": false,
     "grade_id": "cell-b51e0c5b09e4fd07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def drug_dataloader(file_path=\"drug200_numeric.csv\"):\n",
    "    features, classes = [], []\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    lines = lines[1:]\n",
    "\n",
    "    for line in lines:\n",
    "        values = line.split(',')\n",
    "        age = int(values[0])\n",
    "        sex = int(values[1])\n",
    "        bp = int(values[2])\n",
    "        cholesterol = int(values[3])\n",
    "        na_to_k = float(values[4])\n",
    "\n",
    "        class_value = int(values[5])\n",
    "\n",
    "        features.append(np.array([age, sex, bp, cholesterol, na_to_k]))\n",
    "        classes.append(class_value)\n",
    "\n",
    "    return np.array(features), np.array(classes)\n",
    "\n",
    "features, classes = drug_dataloader()\n",
    "\n",
    "# print(np.matrix(features))\n",
    "# print(np.matrix(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0d6aff4a47b7293a381d15dc1aebd6d",
     "grade": true,
     "grade_id": "cell-a6cc5f408a498169",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert (\n",
    "    adler32(str(features[0][:5] + features[1][:5] + features[2][:5]).encode())\n",
    "    == 2319320757\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân chia tập train-valid-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d75ea90d8d7bf25a287c15a80a269ea",
     "grade": false,
     "grade_id": "cell-a3c318564484782b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134, 5), (66, 5), (134,), (66,))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_test_split(\n",
    "    X: np.ndarray, y: np.ndarray, test_ratio=0.33\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Function for proceduring train, and test sets.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): input features.\n",
    "        y (np.ndarray): input labels.\n",
    "        test_ratio (float, optional): ratio size for test sets. Defaults to 0.33.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: features, label for train, test respectively. \n",
    "        They are represented as numpy array.\n",
    "    \"\"\"\n",
    "    indices = np.random.permutation(len(X))\n",
    "    train_size = int(len(X) * (1 - test_ratio))\n",
    "\n",
    "\n",
    "    X_train, X_test = X[indices[:train_size]], X[indices[train_size:]]\n",
    "    y_train, y_test = y[indices[:train_size]], y[indices[train_size:]]\n",
    "\n",
    "    return (\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "    )\n",
    "\n",
    "# Phân chia tập train, test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, classes)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "772e01c2c9ac9ab9ae269dd79d9c2064",
     "grade": true,
     "grade_id": "cell-2cc71a102b3df50d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "SP = X_train.shape + X_test.shape + y_train.shape + y_test.shape\n",
    "assert adler32(str(SP).encode()) == 889979968"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kz-C6eu2Szmt"
   },
   "source": [
    "## Cây quyết định"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEQ7wvnpSzm3"
   },
   "source": [
    "### Độ lợi thông tin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9doZ5CKSSzm5"
   },
   "source": [
    "Thông tin kỳ vọng (entropy):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmJNW8LxSzm6"
   },
   "source": [
    "$$Entropy=-\\sum_{i}^{n}p_ilog_{2}(p_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-H-41plSzm7"
   },
   "source": [
    "Hàm entropy đạt giá trị nhỏ nhất nếu có một giá trị $p_i=1$, đạt giá trị lớn nhất nếu tất cả các $p_i$ bằng nhau. Những tính chất này của hàm entropy khiến nó được sử dụng trong việc đo độ hỗn loạn của một phép phân chia của ID3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "HGAwlg1dSzm9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c82149b871071c550a9539286c040f7b",
     "grade": false,
     "grade_id": "cell-c917d0fafb4d820c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entropy(counts: List, n_samples: int) -> float:\n",
    "    \"\"\"Function for calculating entropy\n",
    "\n",
    "    Args:\n",
    "        counts (list): list number of samples in each class.\n",
    "        n_samples (int): number of data samples.\n",
    "\n",
    "    Return:\n",
    "        entropy (float).\n",
    "    \"\"\"\n",
    "    if n_samples == 0:\n",
    "        return 0.0\n",
    "\n",
    "    counts = np.array(counts)\n",
    "    probabilities = counts / n_samples\n",
    "    probabilities = probabilities[probabilities > 0]\n",
    "    # print(probabilities)\n",
    "    entropy_value = np.sum(-probabilities * np.log2(probabilities))\n",
    "\n",
    "    return entropy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "EJ7on8pvSznN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "423b4ed2826331d6aa29aad3ad89f92a",
     "grade": false,
     "grade_id": "cell-906add99ae2307c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entropy_of_one_division(division: np.ndarray) -> Tuple[float, int]:\n",
    "    \"\"\"Function for calculating entropy of a divided group of data.\n",
    "\n",
    "    Please note that data may have multiple classes.\n",
    "\n",
    "    Args:\n",
    "        division (np.ndarray): input divided group of data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, int]: entropy of a divided group of data.\n",
    "    \"\"\"\n",
    "    n_samples = len(division)\n",
    "    n_classes = set(division)\n",
    "\n",
    "    counts = []\n",
    "    \n",
    "    for n_class in n_classes:\n",
    "        count = np.sum(division == n_class)\n",
    "        counts.append(count)\n",
    "\n",
    "    # print(counts)\n",
    "    \n",
    "    return entropy(counts, n_samples), n_samples\n",
    "\n",
    "\n",
    "# print(entropy_of_one_division(np.array([1, 2, 3, 2, 1, 1, 5, 4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "3XWpYwi_Lco6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efecfb24e1476d3e5d3442da227c0996",
     "grade": false,
     "grade_id": "cell-ddf2eddaec74f262",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_entropy(y_predict: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"Get entropy for a split.\n",
    "\n",
    "    Args:\n",
    "        y_predict (np.ndarray): the split decision by cutoff, True/Fasle.\n",
    "        y (np.ndarray): grouth truth.\n",
    "\n",
    "    Returns:\n",
    "        s (float): entropy of input split, as real-number represented with float type.\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    entropy_true, n_true = entropy_of_one_division(\n",
    "        y[y_predict]\n",
    "    )  # left hand side entropy\n",
    "    \n",
    "    entropy_false, n_false = entropy_of_one_division(\n",
    "        y[~y_predict]\n",
    "    )  # right hand side entropy\n",
    "    # overall entropy\n",
    "    \n",
    "    # s=?\n",
    "    s = (n_true / n) * entropy_true + (n_false / n) * entropy_false\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fFI9qoMWSznZ"
   },
   "source": [
    "Độ lợi thông tin phân lớp tập D theo thuộc tính A:\n",
    "$$ Gain(A)=Entropy(D)-Entropy_{A}(D)$$\n",
    "\n",
    "Trong ID3, tại mỗi node, thuộc tính được chọn được xác định dựa trên là thuộc tính khiến cho information gain đạt giá trị lớn nhất.\n",
    "\n",
    "Các thuộc tính của tập Iris đều có giá trị liên tục. Do đó ta cần rời rạc hóa cho từng thuộc tính. Cách đơn giản là sử dụng một ngưỡng `cutoff` chia giá trị của dữ liệu trên mỗi thuộc tính sẽ làm 2 phần: `<cutoff` và `>=cutoff`.\n",
    "\n",
    "Để tìm ngưỡng `cutoff` tốt nhất cho mỗi thuộc tính ta lần lượt thay `cutoff` bằng các giá trị của thuộc tính sau đó tính entropy, `cutoff` tốt nhất khi entropy bé nhất \n",
    "\n",
    "$$\\left(\\arg\\min Entropy_{A}(D)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCQvubYDSzna"
   },
   "source": [
    "### Cài đặt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tìm một phân hoạch với một độ lợi thông tin cho trước"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a210b4fbf6c8b48fbb34755d62285624",
     "grade": false,
     "grade_id": "cell-a8b2e0b4ee1a4a63",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_best_split(\n",
    "    col_data: np.ndarray, y: np.ndarray\n",
    ") -> Tuple[np.float64, np.float64]:\n",
    "    \"\"\"Function for calculating minimum entropy for a given attributes and its label.\n",
    "\n",
    "    Args:\n",
    "        col_data (np.ndarray): input column data in training dataset.\n",
    "        y (np.ndarray): given label in the training dataset.\n",
    "\n",
    "    Returns:\n",
    "        min_entropy, cutoff (Tuple[np.float64, np.float64]): the minimum entropy, and cut-off value.\n",
    "    \"\"\"\n",
    "    min_entropy = float(\"inf\")\n",
    "    cutoff = None\n",
    "\n",
    "    # Loop through col_data find cutoff where entropy is minimum\n",
    "    for value in set(col_data):\n",
    "        y_predict = col_data < value\n",
    "        my_entropy = get_entropy(y_predict, y)\n",
    "\n",
    "        if my_entropy == 0:\n",
    "            return my_entropy, value\n",
    "        \n",
    "        if my_entropy < min_entropy:\n",
    "            min_entropy = my_entropy\n",
    "            cutoff = value\n",
    "\n",
    "    # Return min entropy, and cutoff\n",
    "    return min_entropy, cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split_of_all(\n",
    "    X: np.ndarray, y: np.ndarray\n",
    ") -> Tuple[np.float64, np.float64, np.float64]:\n",
    "    \"\"\"Function for finding one split given an information gain.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): input training dataset.\n",
    "        y (np.ndarray): given label in the training dataset.\n",
    "\n",
    "    Returns:\n",
    "        col_idx, cutoff, min_entropy (Tuple[np.float64, np.float64, np.float64]): return the index \n",
    "        of column with minimum entropy and cut-off value.\n",
    "    \"\"\"\n",
    "    col_idx = None\n",
    "    min_entropy = float(\"inf\")\n",
    "    cutoff = None\n",
    "\n",
    "    for idx, col_data in enumerate(X.T):\n",
    "        entropy, cur_cutoff = find_best_split(col_data, y)\n",
    "\n",
    "        if entropy == 0:  # best entropy\n",
    "            return idx, cur_cutoff, entropy\n",
    "        elif entropy <= min_entropy:\n",
    "            min_entropy = entropy\n",
    "            col_idx = idx\n",
    "            cutoff = cur_cutoff\n",
    "\n",
    "    return col_idx, cutoff, min_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Khớp dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtfit(X: np.ndarray, y: np.ndarray, depth: int = 0) -> dict:\n",
    "    \"\"\"Function for data-fitting with Decision Tree\n",
    "\n",
    "    Node: each node represented by cutoff value and column index, value and children.\n",
    "         - cutoff value is thresold where you divide your attribute,\n",
    "         - column index is your data attribute index,\n",
    "         - value of node is mean value of label indexes,\n",
    "           if a node is leaf all data samples will have same label.\n",
    "\n",
    "    Note that: we divide each attribute into 2 part => each node will have 2 children: left, right.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): training data\n",
    "        y (np.ndarray): label of training data\n",
    "        depth (int, optional): depth of decision tree after training. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        node (dict): return the node that contains cutoff value and column index, value and children.\n",
    "    \"\"\"\n",
    "    # Stop conditions: if all value of y are the same\n",
    "    if np.all(y == y[0]):\n",
    "        return {\"val\": y[0]}\n",
    "\n",
    "    # find one split given an information gain\n",
    "    col_idx, cutoff, entropy = find_best_split_of_all(X, y)\n",
    "    \n",
    "    y_left = y[X[:, col_idx] < cutoff]\n",
    "    y_right = y[X[:, col_idx] >= cutoff]\n",
    "    X_left = X[X[:, col_idx] < cutoff]\n",
    "    X_right = X[X[:, col_idx] >= cutoff]\n",
    "\n",
    "    node = {\n",
    "        \"index_col\": col_idx,\n",
    "        \"cutoff\": cutoff,\n",
    "        \"val\": np.mean(y),\n",
    "        \"left\": None,\n",
    "        \"right\": None\n",
    "    }\n",
    "\n",
    "    node[\"left\"] = dtfit(X_left, y_left, depth + 1)\n",
    "    node[\"right\"] = dtfit(X_right, y_right, depth + 1)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khớp dữ liệu\n",
    "tree = dtfit(X_train, y_train)\n",
    "\n",
    "# import pprint\n",
    "\n",
    "# pprint.pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dtpredict(tree: dict, row: np.ndarray) -> int:\n",
    "    \"\"\"Function for making prediction use trained DT tree on given observation.\n",
    "\n",
    "    Args:\n",
    "        tree (dict): trained DT model which presented as a dict.\n",
    "        row (np.ndarray): given observation which presented as numpy's array.\n",
    "\n",
    "    Returns:\n",
    "        val (int): return the value of node which is mean value of label indexes.\n",
    "    \"\"\"\n",
    "    cur_layer = tree\n",
    "    while \"cutoff\" in cur_layer:\n",
    "        if row[cur_layer[\"index_col\"]] < cur_layer[\"cutoff\"]:\n",
    "            cur_layer = cur_layer[\"left\"]\n",
    "        else:\n",
    "            cur_layer = cur_layer[\"right\"]\n",
    "\n",
    "    return cur_layer.get(\"val\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "282aee67ccd22f460ce05e835feeaafa",
     "grade": true,
     "grade_id": "cell-6b6d83ccf73e5701",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "given_observation = features[81]\n",
    "groud_truth = classes[81]\n",
    "\n",
    "assert groud_truth == _dtpredict(tree, given_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtpredict(tree: dict, data: np.ndarray) -> List:\n",
    "    \"\"\"Function for making prediction with trained DT model on given input observations.\n",
    "\n",
    "    Args:\n",
    "        tree (dict): trained DT model which presented as a dict.\n",
    "        data (np.ndarray): input input observations.\n",
    "\n",
    "    Returns:\n",
    "        pred (List): list of predicted label for input observations.\n",
    "    \"\"\"\n",
    "    pred = []\n",
    "    for _, col in enumerate(data):\n",
    "        pred.append(_dtpredict(tree, col))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5b04c3aec4a04d1b754d2eed25a5c78",
     "grade": true,
     "grade_id": "cell-5b6c8e1cee25bcdc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "given_observations = features[81:118]\n",
    "groud_truth = classes[81:118]\n",
    "\n",
    "res = (groud_truth == dtpredict(tree, given_observations))\n",
    "\n",
    "print(res)\n",
    "\n",
    "assert adler32(str(res).encode()) == 794314306"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ccf05173d9ca663347f077d197818c3",
     "grade": false,
     "grade_id": "cell-0c2efded71f1bf27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tpfptnfn_cal(\n",
    "    y_test: np.ndarray, y_pred: np.ndarray, positive_class: int = 1\n",
    ") -> Tuple[int, int, int, int]:\n",
    "    \"\"\"Function for calculating elements of confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        y_test (np.ndarray): groud truth.\n",
    "        y_pred (np.ndarray): predicted label.\n",
    "        positive_class (int, optional): wanted calculating class. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        true_positives, false_positives, true_negatives, false_negatives (Tuple[int, int, int, int]): Four \n",
    "        basic number for constructing confusion matrix  including true positives, false positives, true negatives, \n",
    "        and false negatives.\n",
    "    \"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for true, pred in zip(y_test, y_pred):\n",
    "        if pred == positive_class:\n",
    "            if true == positive_class:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                false_positives += 1\n",
    "        \n",
    "        else:\n",
    "            if true == positive_class:\n",
    "                false_negatives += 1\n",
    "\n",
    "            else:\n",
    "                true_negatives += 1\n",
    "\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6927cdc8d14b0fbf72e2d450bb396502",
     "grade": true,
     "grade_id": "cell-e812d2f07627ab0f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "tp, fp, tn, fn = tpfptnfn_cal([1, 0, 1, 1, 0, 0, 1], [1, 0, 0, 1, 0, 1, 1])\n",
    "assert adler32((str(tp) + str(fp) + str(tn) + str(fn)).encode()) == 33030344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "pred = dtpredict(tree, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f7ca840730cc097fa7acd021a62001c",
     "grade": false,
     "grade_id": "cell-dd89c2d2cd33974e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(\n",
    "    y_test: np.ndarray, y_pred: np.ndarray\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"Function for calculating metrics of classification problem including accuracy, recall, \n",
    "    precision, and f1-score.\n",
    "\n",
    "    Args:\n",
    "        y_test (np.ndarray): groud truth.\n",
    "        y_pred (np.ndarray): predicted label.\n",
    "\n",
    "    Returns:\n",
    "        acc, precision, recall, f1 (Tuple[float, float, float, float]): return four values \n",
    "        for each metric: accuracy, recall, precision, and f1-score.\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "\n",
    "    noc = len(np.unique(y_test))  # number of classes\n",
    "\n",
    "    tp, fp, tn, fn = tpfptnfn_cal(y_test, y_pred)\n",
    "\n",
    "    acc = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) > 0 else 0\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 9\n",
    "\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9d61f809c4a3483f9cd9d79572d5033",
     "grade": true,
     "grade_id": "cell-57aedef886488c55",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "acc, prec, rec, f1 = calculate_metrics(y_test, pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nghiên cứu về ý nghĩa các độ đo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn hãy trình ý nghĩa từng độ đo, bao gồm accuracy, precision, recall và f-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d227affdb00152670052d2054d15cd2",
     "grade": false,
     "grade_id": "cell-6e87e78bdda8212a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<h1>Ý nghĩa của từng độ đo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-weight: 900\">I. Accuracy (Độ chính xác tổng thể):</h3>\n",
    "<h5 style=\"font-weight: 900\">1.Ý nghĩa:</h5>\n",
    "Accuracy đo lường tỷ lệ phần trăm mẫu được dự đoán đúng trong tổng số các mẫu. Do đó Accuracy đo lường tỷ lệ dự đoán đúng trên tổng số dự đoán của mô hình. Ví dụ, trong hệ thống phát hiện spam email, nếu trong 100 email, mô hình dự đoán đúng 90 email (Bao gồm cả các email spam và không spam), accuracy sẽ là 90%.\n",
    "<h5 style=\"font-weight: 900\">2. Công thức:</h5>\n",
    "\n",
    "Accuracy = $\\dfrac{\\text{Số dự đoán đúng}}{\\text{Tổng số mẫu}}$\n",
    "\n",
    "Hoặc:\n",
    "\n",
    "Accuracy = $\\dfrac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "Trong đó:\n",
    "- **TP (True Positives):** Số trường hợp dự đoán đúng là dương tính\n",
    "- **FP (False Positives):** Số trường hợp dự đoán đúng là âm tính\n",
    "- **TN (True Negatives):** Số trường hợp dự đoán nhầm là dương tính (Type I Error)\n",
    "- **FN (False Negatives):** Số trường hợp dự đoán nhầm là âm tính (Type II Error)\n",
    "\n",
    "**Lưu ý:** Accuracy không phù hợp khi dữ liệu bị mất cân bằng. Chẳng hạn, nếu 95% email là không spam, một mô hình đơn giản luôn dự đoán \"không spam\" sẽ có accuracy là 95% nhưng thực tế thì nó hoàn toàn vô dụng trong việc phát hiện spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-weight: 900\">II. Precision (Độ chính xác):</h3>\n",
    "<h5 style=\"font-weight: 900\">1.Ý nghĩa:</h5>\n",
    "Precision đo lường tỷ lệ các dự đoán đúng là dương tính trong tổng số các dự đoán đúng. Do đó Precision tập trung vào chất lượng của các dự đoán dương tính. Do đó Precision tập trung vào chất lượng của các dự đoán dương tính. Ví dụ về spam thì precision sẽ cho biết trong số các email mô hình dự đoán là spam thì sẽ có bao nhiêu thực sự là spam. Nếu mô hình dự đoán 10 email là spam, trong đó 8 email thực sự là spam thì precision sẽ là 80%. Precision cao nghĩa là khi mô hình nói một email là spam thì chúng ta có thể khá tin tưởng vào dự đoán đó. Điều này hữu ích trong các ứng dụng cần độ chính xác cao như chẩn đoán y tế.\n",
    "<h5 style=\"font-weight: 900\">2. Công thức:</h5>\n",
    "\n",
    "Precision = $\\dfrac{TP}{TP + FP}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-weight: 900\">III. Recall (Độ nhạy):</h3>\n",
    "<h5 style=\"font-weight: 900\">1.Ý nghĩa:</h5>\n",
    "Recall đo lường tỷ lệ các dự đoán đúng là dương tính (TP) mà mô hình có thể dự đoán đúng trên tổng số các mẫu dương tính thật sự. Vú dụ với spam, nếu có 20 email spam thực sự, và mô hình phát hiện được 15 trong số đó thì recall sẽ là 75%. Recall cao cho thấy mô hình ít bỏ sót các trường hợp cần phát hiện. Do đó, recall có ý nghĩa đặc biệt quan trọng trong các ngành an ninh, y tế.\n",
    "<h5 style=\"font-weight: 900\">2. Công thức:</h5>\n",
    "\n",
    "Precision = $\\dfrac{TP}{TP + FN}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-weight: 900\">IV. F-score:</h3>\n",
    "<h5 style=\"font-weight: 900\">1.Ý nghĩa:</h5>\n",
    "F-score là sự kết hợp cả precision và recall thành một chỉ số duy nhất, giúp cân bằng hai yếu tố trên. F-score thấp nếu một trong hai độ đo precision hoặc recall thấp và cao khi cả hai đều cao.\n",
    "\n",
    "Các biến thể của F-score\n",
    "- F1-score: Cân bằng giữa precision và recall\n",
    "- F2-score: Đề cao recall hơn precision\n",
    "- F0.5-score: Đề cao precision hơn recall\n",
    "\n",
    "Trade-off giữa precision và recall:\n",
    "Trong thực tê, thường sẽ có sự đánh đổi giữa precision và recall. Ví dụ, trong hệ thống phát hiện spam thì nếu ta muốn chắc chắn không bỏ sót email spam nào (recall cao) thì có thể ta phải chấp nhận việc một số email bình thường bị đánh nhầm là spam (precision thấp).\n",
    "\n",
    "- Tăng threshold phân loại -> precision tăng, recall giảm\n",
    "- Giảm threshold phân loại -> precision giảm, recall tăng\n",
    "\n",
    "Ví dụ về trade-off trong thực tế: Hệ thống chẩn đoán ung thư:\n",
    "- Threshold cao: Ít cảnh báo sai (precision cao) nhưng có thể bỏ sót ca bênh (recall thấp)\n",
    "- Threshold thấp: Phát hiện nhiều ca bênh (recall cao) nhưng nhiều cảnh báo sai (precision thấp)\n",
    "<h5 style=\"font-weight: 900\">2. Công thức:</h5>\n",
    "\n",
    "Precision = $\\dfrac{2\\times{\\text{precision}}\\times{\\text{recall}} }{\\text{precision + recall}}$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab03-Clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
